# Generated from /home/khanh/Documents/schoolLife/201/PPL/testAss/BKIT.g4 by ANTLR 4.8
from antlr4 import *
from io import StringIO
from typing.io import TextIO
import sys


from lexererr import *



def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2\32")
        buf.write("\u009f\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
        buf.write("\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r")
        buf.write("\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23")
        buf.write("\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30")
        buf.write("\4\31\t\31\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36")
        buf.write("\t\36\3\2\6\2?\n\2\r\2\16\2@\3\3\3\3\3\3\3\3\3\3\7\3H")
        buf.write("\n\3\f\3\16\3K\13\3\3\4\3\4\3\4\7\4P\n\4\f\4\16\4S\13")
        buf.write("\4\5\4U\n\4\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3\6\3\6\3\6\3")
        buf.write("\6\3\6\3\6\3\6\3\7\3\7\3\b\3\b\3\t\3\t\3\t\3\n\5\nm\n")
        buf.write("\n\3\13\3\13\6\13q\n\13\r\13\16\13r\3\f\6\fv\n\f\r\f\16")
        buf.write("\fw\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3\20\3\21")
        buf.write("\3\21\3\22\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26")
        buf.write("\3\27\3\27\3\30\3\30\3\31\3\31\3\32\3\32\3\33\3\33\3\34")
        buf.write("\3\34\3\35\3\35\3\36\3\36\2\2\37\3\3\5\4\7\5\t\6\13\7")
        buf.write("\r\2\17\2\21\2\23\2\25\2\27\b\31\t\33\n\35\13\37\f!\r")
        buf.write("#\16%\17\'\20)\21+\22-\23/\24\61\25\63\26\65\27\67\30")
        buf.write("9\31;\32\3\2\5\3\2c|\3\2\62;\5\2\13\f\17\17\"\"\2\u00a0")
        buf.write("\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13")
        buf.write("\3\2\2\2\2\27\3\2\2\2\2\31\3\2\2\2\2\33\3\2\2\2\2\35\3")
        buf.write("\2\2\2\2\37\3\2\2\2\2!\3\2\2\2\2#\3\2\2\2\2%\3\2\2\2\2")
        buf.write("\'\3\2\2\2\2)\3\2\2\2\2+\3\2\2\2\2-\3\2\2\2\2/\3\2\2\2")
        buf.write("\2\61\3\2\2\2\2\63\3\2\2\2\2\65\3\2\2\2\2\67\3\2\2\2\2")
        buf.write("9\3\2\2\2\2;\3\2\2\2\3>\3\2\2\2\5B\3\2\2\2\7L\3\2\2\2")
        buf.write("\tV\3\2\2\2\13Z\3\2\2\2\rd\3\2\2\2\17f\3\2\2\2\21h\3\2")
        buf.write("\2\2\23l\3\2\2\2\25n\3\2\2\2\27u\3\2\2\2\31{\3\2\2\2\33")
        buf.write("}\3\2\2\2\35\177\3\2\2\2\37\u0081\3\2\2\2!\u0083\3\2\2")
        buf.write("\2#\u0085\3\2\2\2%\u0087\3\2\2\2\'\u0089\3\2\2\2)\u008b")
        buf.write("\3\2\2\2+\u008d\3\2\2\2-\u008f\3\2\2\2/\u0091\3\2\2\2")
        buf.write("\61\u0093\3\2\2\2\63\u0095\3\2\2\2\65\u0097\3\2\2\2\67")
        buf.write("\u0099\3\2\2\29\u009b\3\2\2\2;\u009d\3\2\2\2=?\t\2\2\2")
        buf.write(">=\3\2\2\2?@\3\2\2\2@>\3\2\2\2@A\3\2\2\2A\4\3\2\2\2BI")
        buf.write("\5\3\2\2CD\5\35\17\2DE\5\r\7\2EF\5\37\20\2FH\3\2\2\2G")
        buf.write("C\3\2\2\2HK\3\2\2\2IG\3\2\2\2IJ\3\2\2\2J\6\3\2\2\2KI\3")
        buf.write("\2\2\2LT\5\5\3\2MQ\7.\2\2NP\5\5\3\2ON\3\2\2\2PS\3\2\2")
        buf.write("\2QO\3\2\2\2QR\3\2\2\2RU\3\2\2\2SQ\3\2\2\2TM\3\2\2\2T")
        buf.write("U\3\2\2\2U\b\3\2\2\2VW\7X\2\2WX\7c\2\2XY\7t\2\2Y\n\3\2")
        buf.write("\2\2Z[\7H\2\2[\\\7w\2\2\\]\7p\2\2]^\7e\2\2^_\7v\2\2_`")
        buf.write("\7k\2\2`a\7q\2\2ab\7p\2\2bc\7<\2\2c\f\3\2\2\2de\t\3\2")
        buf.write("\2e\16\3\2\2\2fg\7\60\2\2g\20\3\2\2\2hi\7g\2\2ij\5\23")
        buf.write("\n\2j\22\3\2\2\2km\7/\2\2lk\3\2\2\2lm\3\2\2\2m\24\3\2")
        buf.write("\2\2np\5\21\t\2oq\5\r\7\2po\3\2\2\2qr\3\2\2\2rp\3\2\2")
        buf.write("\2rs\3\2\2\2s\26\3\2\2\2tv\t\4\2\2ut\3\2\2\2vw\3\2\2\2")
        buf.write("wu\3\2\2\2wx\3\2\2\2xy\3\2\2\2yz\b\f\2\2z\30\3\2\2\2{")
        buf.write("|\7}\2\2|\32\3\2\2\2}~\7\177\2\2~\34\3\2\2\2\177\u0080")
        buf.write("\7]\2\2\u0080\36\3\2\2\2\u0081\u0082\7_\2\2\u0082 \3\2")
        buf.write("\2\2\u0083\u0084\7*\2\2\u0084\"\3\2\2\2\u0085\u0086\7")
        buf.write("+\2\2\u0086$\3\2\2\2\u0087\u0088\7=\2\2\u0088&\3\2\2\2")
        buf.write("\u0089\u008a\7<\2\2\u008a(\3\2\2\2\u008b\u008c\7.\2\2")
        buf.write("\u008c*\3\2\2\2\u008d\u008e\7?\2\2\u008e,\3\2\2\2\u008f")
        buf.write("\u0090\7-\2\2\u0090.\3\2\2\2\u0091\u0092\7/\2\2\u0092")
        buf.write("\60\3\2\2\2\u0093\u0094\7,\2\2\u0094\62\3\2\2\2\u0095")
        buf.write("\u0096\7\61\2\2\u0096\64\3\2\2\2\u0097\u0098\13\2\2\2")
        buf.write("\u0098\66\3\2\2\2\u0099\u009a\13\2\2\2\u009a8\3\2\2\2")
        buf.write("\u009b\u009c\13\2\2\2\u009c:\3\2\2\2\u009d\u009e\13\2")
        buf.write("\2\2\u009e<\3\2\2\2\n\2@IQTlrw\3\b\2\2")
        return buf.getvalue()


class BKITLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    ID = 1
    VAR_ID = 2
    VAR_LIST = 3
    VAR = 4
    FUNCTION = 5
    WS = 6
    LB = 7
    RB = 8
    LK = 9
    RK = 10
    LP = 11
    RP = 12
    SEMI = 13
    COLON = 14
    CM = 15
    EQ = 16
    ADDOP = 17
    SUBOP = 18
    MULOP = 19
    DIVOP = 20
    ERROR_CHAR = 21
    UNCLOSE_STRING = 22
    ILLEGAL_ESCAPE = 23
    UNTERMINATED_COMMENT = 24

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "'Var'", "'Function:'", "'{'", "'}'", "'['", "']'", "'('", "')'", 
            "';'", "':'", "','", "'='", "'+'", "'-'", "'*'", "'/'" ]

    symbolicNames = [ "<INVALID>",
            "ID", "VAR_ID", "VAR_LIST", "VAR", "FUNCTION", "WS", "LB", "RB", 
            "LK", "RK", "LP", "RP", "SEMI", "COLON", "CM", "EQ", "ADDOP", 
            "SUBOP", "MULOP", "DIVOP", "ERROR_CHAR", "UNCLOSE_STRING", "ILLEGAL_ESCAPE", 
            "UNTERMINATED_COMMENT" ]

    ruleNames = [ "ID", "VAR_ID", "VAR_LIST", "VAR", "FUNCTION", "NUMBER", 
                  "DOT", "EXPO", "SIGN", "SCIEN", "WS", "LB", "RB", "LK", 
                  "RK", "LP", "RP", "SEMI", "COLON", "CM", "EQ", "ADDOP", 
                  "SUBOP", "MULOP", "DIVOP", "ERROR_CHAR", "UNCLOSE_STRING", 
                  "ILLEGAL_ESCAPE", "UNTERMINATED_COMMENT" ]

    grammarFileName = "BKIT.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.8")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


    def emit(self):
        tk = self.type
        result = super().emit()
        if tk == self.UNCLOSE_STRING:       
            raise UncloseString(result.text)
        elif tk == self.ILLEGAL_ESCAPE:
            raise IllegalEscape(result.text)
        elif tk == self.ERROR_CHAR:
            raise ErrorToken(result.text)
        elif tk == self.UNTERMINATED_COMMENT:
            raise UnterminatedComment()
        else:
            return result;


